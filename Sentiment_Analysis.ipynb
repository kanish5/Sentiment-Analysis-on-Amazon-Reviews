{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhua5bgGhvru",
        "outputId": "44d6e105-6a85-4eed-a3bf-936b271793a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-29e7d3583bda>:14: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      0.11      0.19       157\n",
            "     neutral       0.50      0.06      0.11       278\n",
            "    positive       0.94      1.00      0.97      6491\n",
            "\n",
            "    accuracy                           0.94      6926\n",
            "   macro avg       0.65      0.39      0.42      6926\n",
            "weighted avg       0.92      0.94      0.92      6926\n",
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            " [[  18    7  132]\n",
            " [   8   18  252]\n",
            " [  10   11 6470]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# ðŸ“¦ Step 1: Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# ðŸ“¥ Step 2: Load dataset\n",
        "df = pd.read_csv('Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
        "df = df[['reviews.text', 'reviews.rating']].dropna()\n",
        "df = df.rename(columns={'reviews.text': 'review', 'reviews.rating': 'rating'})\n",
        "df = df[df['rating'].isin([1, 2, 3, 4, 5])]  # Filter only valid ratings\n",
        "\n",
        "# ðŸ·ï¸ Step 3: Create sentiment labels from rating\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating <= 2:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df['label'] = df['rating'].apply(label_sentiment)\n",
        "\n",
        "# ðŸ§¹ Step 4: Text preprocessing\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  # remove non-letter characters\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['cleaned_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# âœ‚ï¸ Step 5: Prepare features and labels\n",
        "X = df['cleaned_review']\n",
        "y = df['label']\n",
        "\n",
        "# ðŸ”¤ Step 6: Convert text to TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_vect = vectorizer.fit_transform(X)\n",
        "\n",
        "# ðŸŽ¯ Step 7: Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ðŸ¤– Step 8: Train a Logistic Regression classifier\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ðŸ§ª Step 9: Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ðŸ§¾ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ðŸ’¾ Step 10: Save the model and vectorizer (optional)\n",
        "joblib.dump(model, 'sentiment_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
      ]
    }
  ]
}